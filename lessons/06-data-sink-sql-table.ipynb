{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import spark_partition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "      .setMaster(\"local[3]\") \\\n",
    "      .setAppName(\"SparkSQLTable\")\n",
    "\n",
    "spark = SparkSession \\\n",
    "      .builder \\\n",
    "      .config(conf=conf) \\\n",
    "      .enableHiveSupport() \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|ORIGIN_CITY_NAME|DEST|DEST_CITY_NAME|CRS_DEP_TIME|DEP_TIME|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|CANCELLED|DISTANCE|\n",
      "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
      "|2000-01-01|        DL|             1451|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1115|    1113|     1343|      5|        1400|    1348|        0|     946|\n",
      "|2000-01-01|        DL|             1479|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1315|    1311|     1536|      7|        1559|    1543|        0|     946|\n",
      "|2000-01-01|        DL|             1857|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1415|    1414|     1642|      9|        1721|    1651|        0|     946|\n",
      "|2000-01-01|        DL|             1997|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1715|    1720|     1955|     10|        2013|    2005|        0|     946|\n",
      "|2000-01-01|        DL|             2065|   BOS|      Boston, MA| ATL|   Atlanta, GA|        2015|    2010|     2230|     10|        2300|    2240|        0|     946|\n",
      "|2000-01-01|        US|             2619|   BOS|      Boston, MA| ATL|   Atlanta, GA|         650|     649|      956|      7|         955|    1003|        0|     946|\n",
      "|2000-01-01|        US|             2621|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1440|    1446|     1713|      4|        1738|    1717|        0|     946|\n",
      "|2000-01-01|        DL|              346|   BTR| Baton Rouge, LA| ATL|   Atlanta, GA|        1740|    1744|     1957|      9|        2008|    2006|        0|     449|\n",
      "|2000-01-01|        DL|              412|   BTR| Baton Rouge, LA| ATL|   Atlanta, GA|        1345|    1345|     1552|      9|        1622|    1601|        0|     449|\n",
      "|2000-01-01|        DL|              299|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|        1245|    1245|     1443|      5|        1455|    1448|        0|     712|\n",
      "|2000-01-01|        DL|              495|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|        2035|    2035|     2226|      9|        2241|    2235|        0|     712|\n",
      "|2000-01-01|        DL|              677|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|         710|     710|      940|      7|         925|     947|        0|     712|\n",
      "|2000-01-01|        DL|              251|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        2040|    2100|     2235|      7|        2233|    2242|        0|     576|\n",
      "|2000-01-01|        DL|             1003|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1635|    1838|     2020|     12|        1832|    2032|        0|     576|\n",
      "|2000-01-01|        DL|             1501|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1430|    1435|     1623|     12|        1634|    1635|        0|     576|\n",
      "|2000-01-01|        DL|             1907|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|         530|     530|      716|      4|         723|     720|        0|     576|\n",
      "|2000-01-01|        DL|             2063|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1250|    null|     null|   null|        1449|    null|        1|     576|\n",
      "|2000-01-01|        DL|             2111|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1845|    1855|     2041|      9|        2046|    2050|        0|     576|\n",
      "|2000-01-01|        US|             2632|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|         710|     710|     null|   null|         905|    null|        0|     576|\n",
      "|2000-01-01|        US|             2967|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1700|    1700|     1845|      6|        1853|    1851|        0|     576|\n",
      "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_parquet_df = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .load(\"./../data/flight*.parquet\") \n",
    "\n",
    "flight_parquet_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS airline_db\")\n",
    "spark.catalog.setCurrentDatabase(\"airline_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/25 23:47:25 WARN HadoopFSUtils: The directory file:/Users/johnbelga/workspace/python/spark/lab/lessons/spark-warehouse/airline_db.db/flight_data_tbl was not found. Was it deleted very recently?\n",
      "23/08/25 23:47:25 WARN FileUtils: File file:/Users/johnbelga/workspace/python/spark/lab/lessons/spark-warehouse/airline_db.db/flight_data_tbl does not exist; Force to delete it.\n",
      "23/08/25 23:47:25 ERROR FileUtils: Failed to delete file:/Users/johnbelga/workspace/python/spark/lab/lessons/spark-warehouse/airline_db.db/flight_data_tbl\n",
      "23/08/25 23:47:28 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `spark_catalog`.`airline_db`.`flight_data_tbl` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n",
      "23/08/25 23:47:28 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "23/08/25 23:47:28 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "23/08/25 23:47:28 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "23/08/25 23:47:28 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    }
   ],
   "source": [
    "flight_parquet_df.write \\\n",
    "      .format(\"csv\") \\\n",
    "      .mode(\"overwrite\") \\\n",
    "      .bucketBy(5, \"OP_CARRIER\", \"ORIGIN\") \\\n",
    "      .sortBy(\"OP_CARRIER\", \"ORIGIN\") \\\n",
    "      .saveAsTable(\"flight_data_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
